{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROM Video Analyzing\n",
    "* To run this note, you need to install Openpose following [Steps to Install Openpose in ComputeCanada Cluster](https://docs.google.com/document/d/1vQCQD2iet-K1ZAjTns2aEp-q7R-w8fCQ55jVzriWLV0/edit?usp=sharing)\n",
    "* To set up Jupyter Notebook and submit jobs in Compute Canada Clusters, please refer to [Steps to Use Openpose Analyzing Video](https://docs.google.com/document/d/1tozpc-KpAHVjQOx5XkW0pDYbd8IKKCD45Omk-RvFNcg/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('module load nixpkgs/16.09  gcc/5.4.0  cuda/8.0.44  cudnn/7.0 opencv/3.3.0  boost/1.65.1 openblas/0.2.20 hdf5/1.8.18 leveldb/1.18 mkl-dnn/0.14 python/3.5.2')\n",
    "os.system('cd ~')\n",
    "os.system('source openposeEnv_Python3/bin/activate')\n",
    "os.system('export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/openpose_python_lib/lib:$HOME/openpose_python_lib/python/openpose:$HOME/caffe/build/lib:/cvmfs/soft.computecanada.ca/easybuild/software/2017/avx2/Compiler/gcc5.4/boost/1.65.1/lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Python\n",
    "# It requires OpenCV installed for Python\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "from sys import platform\n",
    "import argparse\n",
    "\n",
    "import pdb\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "# Remember to add your installation path here\n",
    "# Option b\n",
    "# If you run `make install` (default path is `/usr/local/python` for Ubuntu), you can also access the OpenPose/python module from there. This will install OpenPose and the python library at your desired installation path. Ensure that this is in your python path in order to use it.\n",
    "sys.path.insert(0,r'/home/lingheng/openpose_python_lib/python/openpose') \n",
    "\n",
    "# Parameters for OpenPose. Take a look at C++ OpenPose example for meaning of components. Ensure all below are filled\n",
    "try:\n",
    "    from openpose import *\n",
    "except:\n",
    "    raise Exception('Error: OpenPose library could not be found. Did you enable `BUILD_PYTHON` in CMake and have this Python script in the right folder?')\n",
    "params = dict()\n",
    "params[\"logging_level\"] = 3\n",
    "params[\"output_resolution\"] = \"-1x-1\"\n",
    "params[\"net_resolution\"] = \"-1x368\" # if crop video, this should be changged and must be mutplies of 16.\n",
    "params[\"model_pose\"] = \"BODY_25\"\n",
    "params[\"alpha_pose\"] = 0.6\n",
    "params[\"scale_gap\"] = 0.3\n",
    "params[\"scale_number\"] = 1\n",
    "params[\"render_threshold\"] = 0.05\n",
    "# If GPU version is built, and multiple GPUs are available, set the ID here\n",
    "params[\"num_gpu_start\"] = 0\n",
    "params[\"disable_blending\"] = False\n",
    "# Ensure you point to the correct path where models are located\n",
    "params[\"default_model_folder\"] = \"/home/lingheng/openpose/models/\"\n",
    "# Construct OpenPose object allocates GPU memory\n",
    "openpose = OpenPose(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw frames per second: 30.00063026534171\n",
      "Frame width:1152, Frame height:972.\n"
     ]
    }
   ],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "args = dict()\n",
    "args['video']='/home/lingheng/project/lingheng/ROM_Video_Process/Openpose_Video_Analysis_Code/test_video.mp4'\n",
    "args['output_directory']='/home/lingheng/project/lingheng/ROM_Video_Process/Openpose_Video_Analysis_Code'\n",
    "\n",
    "if args.get(\"video\", None) is None:\n",
    "    raise Error(\"No input video!!\")\n",
    "# otherwise, we are reading from a video file\n",
    "else:\n",
    "    camera = cv2.VideoCapture(args[\"video\"])\n",
    "# frames per second (fps) in the raw video\n",
    "fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = 1\n",
    "print(\"Raw frames per second: {0}\".format(fps))\n",
    "# prepare to save video\n",
    "(grabbed, frame) = camera.read()\n",
    "## downsample frame\n",
    "#downsample_rate = 0.5\n",
    "#frame = cv2.resize(frame,None,fx=downsample_rate, fy=downsample_rate, interpolation = cv2.INTER_LINEAR)\n",
    "# crop frame\n",
    "original_h, original_w, channels= frame.shape\n",
    "top_edge = int(original_h*(1/10))\n",
    "down_edge = int(original_h*1)\n",
    "left_edge = int(original_w*(1/5))\n",
    "right_edge = int(original_w*(4/5))\n",
    "frame_cropped = frame[top_edge:down_edge,left_edge:right_edge,:].copy() # must use copy(), otherwise slice only return address i.e. not hard copy\n",
    "\n",
    "cropped_h, cropped_w, channels = frame_cropped.shape\n",
    "fwidth = cropped_w \n",
    "fheight = cropped_h\n",
    "print(\"Frame width:{}, Frame height:{}.\".format(cropped_w , cropped_h))\n",
    "# Define the polygon of Core Interest Area\n",
    "point_1 = [int(0.17 * cropped_w), int(0.20 * cropped_h)]\n",
    "point_2 = [int(0.17 * cropped_w), int(0.62 * cropped_h)]\n",
    "point_3 = [int(0.44 * cropped_w), int(0.82 * cropped_h)]\n",
    "point_4 = [int(0.61 * cropped_w), int(0.72 * cropped_h)]\n",
    "point_5 = [int(0.61 * cropped_w), int(0.20 * cropped_h)]\n",
    "core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "\n",
    "# get output video file name\n",
    "file_path = args[\"video\"].split('/')\n",
    "file_name, _= file_path[-1].split('.')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out_camera_frame_whole = cv2.VideoWriter(os.path.join(args['output_directory'],'{}_processed_whole.avi'.format(file_name)),fourcc, fps, (fwidth,fheight))\n",
    "out_camera_frame_core = cv2.VideoWriter(os.path.join(args['output_directory'],'{}_processed_core.avi'.format(file_name)),fourcc, fps, (fwidth,fheight))\n",
    "out_camera_frame_margin = cv2.VideoWriter(os.path.join(args['output_directory'],'{}_processed_margin.avi'.format(file_name)),fourcc, fps, (fwidth,fheight))\n",
    "# get output estimated occupancy file name\n",
    "out_occupancy_whole = os.path.join(args['output_directory'],'{}_processed_occupancy_whole.txt'.format(file_name))\n",
    "out_occupancy_core = os.path.join(args['output_directory'],'{}_processed_occupancy_core.txt'.format(file_name))\n",
    "out_occupancy_margin = os.path.join(args['output_directory'],'{}_processed_occupancy_margin.txt'.format(file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1428.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera.get(cv2.CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame: 0\n",
      "Processing frame: 200\n",
      "Processing frame: 400\n",
      "Processing frame: 600\n",
      "Processing frame: 800\n",
      "Processing frame: 1000\n",
      "Processing frame: 1200\n",
      "Processing frame: 1400\n",
      "Frame: 1427, grabbed=False and frame=None\n"
     ]
    }
   ],
   "source": [
    "# loop over the frames of the video\n",
    "total_frame_number = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "for frame_count in range(int(total_frame_number)):\n",
    "    if frame_count % 200 == 0:\n",
    "        print('Processing frame: {}'.format(frame_count))\n",
    "    (grabbed, frame) = camera.read()\n",
    "    if grabbed == True:\n",
    "        time = camera.get(cv2.CAP_PROP_POS_MSEC) #Current position of the video file in milliseconds.\n",
    "        ## downsample frame\n",
    "        #frame = cv2.resize(frame,None,fx=downsample_rate, fy=downsample_rate, interpolation = cv2.INTER_LINEAR)\n",
    "        # crop frame\n",
    "        frame_cropped = frame[top_edge:down_edge,left_edge:right_edge,:].copy() # must use copy()\n",
    "        \n",
    "        # 1. Whole Interest Area\n",
    "        # Output keypoints and the image with the human skeleton blended on it\n",
    "        keypoints_whole_interest_area, output_image_whole_interest_area = openpose.forward(frame_cropped, True)\n",
    "        \n",
    "        # 2. Core Interest Area\n",
    "        core_interest_area_mask = np.zeros(frame_cropped.shape[:2], np.uint8)\n",
    "        cv2.drawContours(core_interest_area_mask, [core_interest_area_polygon], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "        core_interest_area = cv2.bitwise_and(frame_cropped, frame_cropped, mask=core_interest_area_mask)\n",
    "        keypoints_core_interest_area, output_image_core_interest_area = openpose.forward(core_interest_area, True)\n",
    "        # 3. Margin Interest Area\n",
    "        margin_interest_area = cv2.bitwise_xor(frame_cropped, core_interest_area)\n",
    "        keypoints_margin_interest_area, output_image_margin_interest_area = openpose.forward(margin_interest_area, True)\n",
    "        \n",
    "        # draw the text and timestamp on the frame\n",
    "        occupancy_whole = keypoints_whole_interest_area.shape[0]\n",
    "        occupancy_core = keypoints_core_interest_area.shape[0]\n",
    "        occupancy_margin = keypoints_margin_interest_area.shape[0]\n",
    "        \n",
    "        cv2.putText(output_image_whole_interest_area, \"Whole Occupancy: {}\".format(occupancy_whole), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(output_image_core_interest_area, \"Core Occupancy: {}\".format(occupancy_core), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(output_image_margin_interest_area, \"Margin Occupancy: {}\".format(occupancy_margin), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        \n",
    "        # save estimated occupancy data\n",
    "        with open(out_occupancy_whole, \"a+\") as fh:\n",
    "           fh.write(\"{},{}\\r\".format(time, occupancy_whole))\n",
    "        with open(out_occupancy_core, \"a+\") as fh:\n",
    "           fh.write(\"{},{}\\r\".format(time, occupancy_core))\n",
    "        with open(out_occupancy_margin, \"a+\") as fh:\n",
    "           fh.write(\"{},{}\\r\".format(time, occupancy_margin))\n",
    "        # save processed videos\n",
    "        out_camera_frame_whole.write(output_image_whole_interest_area)\n",
    "        out_camera_frame_core.write(output_image_core_interest_area)\n",
    "        out_camera_frame_margin.write(output_image_margin_interest_area)\n",
    "    else:\n",
    "        # Pass this frame if cannot grab an image.\n",
    "        print('Frame: {}, grabbed={} and frame={}'.format(frame_count, grabbed, frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

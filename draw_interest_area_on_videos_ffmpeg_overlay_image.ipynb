{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Interst Area Boundaries On Videos: ffmpeg overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Polygon with Transparent Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: camera1_transparent_img.png\n",
      "Generated: camera2_transparent_img.png\n"
     ]
    }
   ],
   "source": [
    "original_h = 1080\n",
    "original_w = 1920\n",
    "\n",
    "cameras = [1, 2]\n",
    "for camera_index in cameras:\n",
    "    # Define the polygon of Whole Interest Area for videos from Camera1 or Camera2\n",
    "    if camera_index == 1:\n",
    "        # crop frame: Camera1\n",
    "        top_edge = int(original_h*(1/10))\n",
    "        down_edge = int(original_h*1)\n",
    "        left_edge = int(original_w*(1/5))\n",
    "        right_edge = int(original_w*(4/5))\n",
    "        point_1 = [left_edge, top_edge]\n",
    "        point_2 = [left_edge, down_edge]\n",
    "        point_3 = [right_edge, down_edge]\n",
    "        point_4 = [right_edge, top_edge]\n",
    "        whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "    elif camera_index == 2:\n",
    "        # crop frame: Camera2\n",
    "        top_edge = int(original_h*(1/10))\n",
    "        down_edge = int(original_h*(4/5))\n",
    "        left_edge = int(original_w*(2.5/5))\n",
    "        right_edge = int(original_w*(1))\n",
    "        point_1 = [left_edge, top_edge]\n",
    "        point_2 = [left_edge, down_edge]\n",
    "        point_3 = [right_edge, down_edge]\n",
    "        point_4 = [right_edge, top_edge]\n",
    "        whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "    else:\n",
    "        # crop frame: test video\n",
    "        top_edge = int(original_h*(1/10))\n",
    "        down_edge = int(original_h*1)\n",
    "        left_edge = int(original_w*(1/5))\n",
    "        right_edge = int(original_w*(4/5))\n",
    "        print('Polygon: Video not from Camera1 or Camera2!')\n",
    "        point_1 = [left_edge, top_edge]\n",
    "        point_2 = [left_edge, down_edge]\n",
    "        point_3 = [right_edge, down_edge]\n",
    "        point_4 = [right_edge, top_edge]\n",
    "        whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "\n",
    "    # Define the polygon of Core Interest Area for videos from Camera1 or Camera2\n",
    "    cropped_w = right_edge - left_edge\n",
    "    cropped_h = down_edge - top_edge\n",
    "    if camera_index == 1:\n",
    "        # polygon for Camera1\n",
    "        point_1 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        point_2 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.62 * cropped_h)]\n",
    "        point_3 = [left_edge + int(0.44 * cropped_w), top_edge + int(0.82 * cropped_h)]\n",
    "        point_4 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.72 * cropped_h)]\n",
    "        point_5 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "    elif camera_index == 2:\n",
    "        # polygon for Camera2\n",
    "        point_1 = [left_edge + int(0.15 * cropped_w), top_edge + int(0.05 * cropped_h)]\n",
    "        point_2 = [left_edge + int(0.15 * cropped_w), top_edge + int(0.65 * cropped_h)]\n",
    "        point_3 = [left_edge + int(0.95 * cropped_w), top_edge + int(0.75 * cropped_h)]\n",
    "        point_4 = [left_edge + int(0.95 * cropped_w), top_edge + int(0.05 * cropped_h)]\n",
    "        core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "    else:\n",
    "        # polygon for test video\n",
    "        point_1 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        point_2 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.62 * cropped_h)]\n",
    "        point_3 = [left_edge + int(0.44 * cropped_w), top_edge + int(0.82 * cropped_h)]\n",
    "        point_4 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.72 * cropped_h)]\n",
    "        point_5 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        print('Polygon: Video not from Camera1 or Camera2!')\n",
    "        core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "\n",
    "    # Define a transparent background\n",
    "    n_channels = 4\n",
    "    transparent_img = np.zeros((original_h, original_w, n_channels))\n",
    "    \n",
    "    cv2.drawContours(transparent_img, [whole_interest_area_polygon], -1, (255, 0, 0, 255), 6, cv2.LINE_AA) # BGR\n",
    "    cv2.drawContours(transparent_img, [core_interest_area_polygon], -1, (0, 0, 255, 255), 6, cv2.LINE_AA)\n",
    "\n",
    "    if camera_index == 1:\n",
    "        cv2.putText(transparent_img, \"Camera View\", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255, 255), 4)\n",
    "        cv2.putText(transparent_img, \"Whole Interest Area\", (left_edge+10, top_edge+80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0, 255), 4)\n",
    "        cv2.putText(transparent_img, \"Core Interest\", (point_1[0]+10, point_1[1]+80), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255, 255), 4)\n",
    "        cv2.putText(transparent_img, \"Area\", (point_1[0]+10, point_1[1]+130), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255, 255), 4)\n",
    "    elif camera_index == 2:\n",
    "        cv2.putText(transparent_img, \"Camera View\", (800, 1000), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255, 255), 4)\n",
    "        cv2.putText(transparent_img, \"Whole Interest Area\", (left_edge+10, down_edge-50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0, 255), 4)\n",
    "        cv2.putText(transparent_img, \"Core Interest Area\", (point_2[0]+10, point_2[1]-50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255, 255), 4)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    cv2.imwrite('camera{}_transparent_img.png'.format(camera_index), transparent_img)\n",
    "    print('Generated: {}'.format('camera{}_transparent_img.png'.format(camera_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using \"ffmpeg overlay\" Processing Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oct_02',\n",
       " 'Oct_03',\n",
       " 'Oct_05',\n",
       " 'Sep_12',\n",
       " 'Sep_13',\n",
       " 'Sep_14',\n",
       " 'Sep_17',\n",
       " 'Sep_18',\n",
       " 'Sep_19',\n",
       " 'Sep_20',\n",
       " 'Sep_21',\n",
       " 'Sep_24',\n",
       " 'Sep_25',\n",
       " 'Sep_26',\n",
       " 'Sep_27',\n",
       " 'Sep_28']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_video_dir = '../ROM_raw_videos'\n",
    "raw_video_sub_dir = os.listdir(raw_video_dir)\n",
    "raw_video_sub_dir.sort()\n",
    "raw_video_sub_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_dir = '../ROM_raw_videos_with_interst_area_ffmpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 files in Sep_17\n",
      "Processing: Camera1_Sep_17_1300_1400_Parameterized_Learning_Agent_with_interest_area.avi\n",
      "code: 0, Elapsed time: 1827.0604043006897s\n"
     ]
    }
   ],
   "source": [
    "raw_video_sub_dir = ['Sep_17']\n",
    "for sub_dir in raw_video_sub_dir:\n",
    "    files_path = glob.glob(os.path.join(raw_video_dir, sub_dir, '*.mp4'))\n",
    "    print('{} files in {}'.format(len(files_path), sub_dir))\n",
    "    \n",
    "    for f_path in files_path:\n",
    "        if 'Camera1' in f_path and '1300' in f_path:\n",
    "            # Load overlay image\n",
    "            if 'Camera1' in f_path:\n",
    "                overlay_image = 'camera1_transparent_img.png'\n",
    "            else:\n",
    "                overlay_image = 'camera2_transparent_img.png'\n",
    "\n",
    "            # Define input filename\n",
    "            input_filename = f_path\n",
    "\n",
    "            # Define output filename\n",
    "            output_video_sub_dir = os.path.join(output_video_dir, sub_dir)\n",
    "            if not os.path.exists(output_video_sub_dir):\n",
    "                os.makedirs(output_video_sub_dir)\n",
    "            f_name = f_path.split('/')[-1]\n",
    "            output_video_filename = os.path.join(output_video_sub_dir,'{}_with_interest_area.avi'.format(f_name.split('.mp4')[0]))\n",
    "            print('Processing: {}'.format(output_video_filename.split('/')[-1]))\n",
    "            start_time = time.time()\n",
    "            # ffmpeg overlay\n",
    "            code = os.system(\"ffmpeg -i {} -i {} -filter_complex \\\"[0:v][1:v] overlay=0:0\\\" -c:a copy {}\".format(input_filename,overlay_image,output_video_filename))\n",
    "            print('code: {}, Elapsed time: {}s'.format(code, time.time() - start_time))\n",
    "                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

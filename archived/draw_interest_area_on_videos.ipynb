{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Interst Area Boundaries On Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oct_02',\n",
       " 'Oct_03',\n",
       " 'Oct_05',\n",
       " 'Sep_12',\n",
       " 'Sep_13',\n",
       " 'Sep_14',\n",
       " 'Sep_17',\n",
       " 'Sep_18',\n",
       " 'Sep_19',\n",
       " 'Sep_20',\n",
       " 'Sep_21',\n",
       " 'Sep_24',\n",
       " 'Sep_25',\n",
       " 'Sep_26',\n",
       " 'Sep_27',\n",
       " 'Sep_28']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_video_dir = '../ROM_raw_videos'\n",
    "raw_video_sub_dir = os.listdir(raw_video_dir)\n",
    "raw_video_sub_dir.sort()\n",
    "raw_video_sub_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_dir = '../ROM_raw_videos_with_interst_area_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 files in Sep_17\n",
      "\n",
      "Camera index: 1\n",
      "Total frame number: 91884.0\n",
      "Processing frame: 0\n",
      "Elapsed time: 4.982948303222656e-05s\n",
      "Processing frame: 2000\n",
      "Elapsed time: 97.65947389602661s\n",
      "Processing frame: 4000\n",
      "Elapsed time: 192.7150013446808s\n",
      "Processing frame: 6000\n",
      "Elapsed time: 293.24481177330017s\n",
      "Processing frame: 8000\n",
      "Elapsed time: 393.25816345214844s\n",
      "Processing frame: 10000\n",
      "Elapsed time: 488.88309693336487s\n",
      "Processing frame: 12000\n",
      "Elapsed time: 585.4023911952972s\n",
      "Processing frame: 14000\n",
      "Elapsed time: 679.3073678016663s\n",
      "Processing frame: 16000\n",
      "Elapsed time: 773.7013690471649s\n",
      "Processing frame: 18000\n",
      "Elapsed time: 869.046807050705s\n",
      "Processing frame: 20000\n",
      "Elapsed time: 970.0736854076385s\n",
      "Processing frame: 22000\n",
      "Elapsed time: 1066.6092867851257s\n",
      "Processing frame: 24000\n",
      "Elapsed time: 1169.443959236145s\n",
      "Processing frame: 26000\n",
      "Elapsed time: 1264.332409620285s\n",
      "Processing frame: 28000\n",
      "Elapsed time: 1359.219486951828s\n",
      "Processing frame: 30000\n",
      "Elapsed time: 1460.7626564502716s\n",
      "Processing frame: 32000\n",
      "Elapsed time: 1553.3337941169739s\n",
      "Processing frame: 34000\n",
      "Elapsed time: 1651.1972613334656s\n",
      "Processing frame: 36000\n",
      "Elapsed time: 1747.2626268863678s\n",
      "Processing frame: 38000\n",
      "Elapsed time: 1847.9537262916565s\n",
      "Processing frame: 40000\n",
      "Elapsed time: 1947.359617948532s\n",
      "Processing frame: 42000\n",
      "Elapsed time: 2045.0587875843048s\n",
      "Processing frame: 44000\n",
      "Elapsed time: 2143.8359677791595s\n",
      "Processing frame: 46000\n",
      "Elapsed time: 2234.7376549243927s\n",
      "Processing frame: 48000\n",
      "Elapsed time: 2334.0319283008575s\n",
      "Processing frame: 50000\n",
      "Elapsed time: 2428.349396944046s\n",
      "Processing frame: 52000\n",
      "Elapsed time: 2523.993824481964s\n",
      "Processing frame: 54000\n",
      "Elapsed time: 2621.644905090332s\n",
      "Processing frame: 56000\n",
      "Elapsed time: 2719.6248109340668s\n",
      "Processing frame: 58000\n",
      "Elapsed time: 2822.2180144786835s\n",
      "Processing frame: 60000\n",
      "Elapsed time: 2918.1589386463165s\n",
      "Processing frame: 62000\n",
      "Elapsed time: 3018.4698719978333s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_video_sub_dir = ['Sep_17']\n",
    "for sub_dir in raw_video_sub_dir:\n",
    "    files_path = glob.glob(os.path.join(raw_video_dir, sub_dir, '*.mp4'))\n",
    "    print('{} files in {}'.format(len(files_path), sub_dir))\n",
    "    \n",
    "    for f_path in files_path:\n",
    "        if '1300' in f_path and 'Camera1' in f_path:\n",
    "            f_name = f_path.split('/')[-1]\n",
    "            print(''.format(f_name))\n",
    "\n",
    "            # Get Camera index\n",
    "            camera_index = int(f_name[6])\n",
    "            print('Camera index: {}'.format(camera_index))\n",
    "\n",
    "            # Get frame size\n",
    "            camera = cv2.VideoCapture(f_path)\n",
    "            (grabbed, frame) = camera.read()\n",
    "            original_h, original_w, channels= frame.shape\n",
    "\n",
    "            # Define the polygon of Whole Interest Area for videos from Camera1 or Camera2\n",
    "            if camera_index == 1:\n",
    "                # crop frame: Camera1\n",
    "                top_edge = int(original_h*(1/10))\n",
    "                down_edge = int(original_h*1)\n",
    "                left_edge = int(original_w*(1/5))\n",
    "                right_edge = int(original_w*(4/5))\n",
    "                point_1 = [left_edge, top_edge]\n",
    "                point_2 = [left_edge, down_edge]\n",
    "                point_3 = [right_edge, down_edge]\n",
    "                point_4 = [right_edge, top_edge]\n",
    "                whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "            elif camera_index == 2:\n",
    "                # crop frame: Camera2\n",
    "                top_edge = int(original_h*(1/10))\n",
    "                down_edge = int(original_h*(4/5))\n",
    "                left_edge = int(original_w*(2.5/5))\n",
    "                right_edge = int(original_w*(1))\n",
    "                point_1 = [left_edge, top_edge]\n",
    "                point_2 = [left_edge, down_edge]\n",
    "                point_3 = [right_edge, down_edge]\n",
    "                point_4 = [right_edge, top_edge]\n",
    "                whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "            else:\n",
    "                # crop frame: test video\n",
    "                top_edge = int(original_h*(1/10))\n",
    "                down_edge = int(original_h*1)\n",
    "                left_edge = int(original_w*(1/5))\n",
    "                right_edge = int(original_w*(4/5))\n",
    "                print('Polygon: Video not from Camera1 or Camera2!')\n",
    "                point_1 = [left_edge, top_edge]\n",
    "                point_2 = [left_edge, down_edge]\n",
    "                point_3 = [right_edge, down_edge]\n",
    "                point_4 = [right_edge, top_edge]\n",
    "                whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "\n",
    "            # Define the polygon of Core Interest Area for videos from Camera1 or Camera2\n",
    "            cropped_w = right_edge - left_edge\n",
    "            cropped_h = down_edge - top_edge\n",
    "            if camera_index == 1:\n",
    "                # polygon for Camera1\n",
    "                point_1 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "                point_2 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.62 * cropped_h)]\n",
    "                point_3 = [left_edge + int(0.44 * cropped_w), top_edge + int(0.82 * cropped_h)]\n",
    "                point_4 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.72 * cropped_h)]\n",
    "                point_5 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "                core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "            elif camera_index == 2:\n",
    "                # polygon for Camera2\n",
    "                point_1 = [left_edge + int(0.15 * cropped_w), top_edge + int(0.05 * cropped_h)]\n",
    "                point_2 = [left_edge + int(0.15 * cropped_w), top_edge + int(0.65 * cropped_h)]\n",
    "                point_3 = [left_edge + int(0.95 * cropped_w), top_edge + int(0.75 * cropped_h)]\n",
    "                point_4 = [left_edge + int(0.95 * cropped_w), top_edge + int(0.05 * cropped_h)]\n",
    "                core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "            else:\n",
    "                # polygon for test video\n",
    "                point_1 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "                point_2 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.62 * cropped_h)]\n",
    "                point_3 = [left_edge + int(0.44 * cropped_w), top_edge + int(0.82 * cropped_h)]\n",
    "                point_4 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.72 * cropped_h)]\n",
    "                point_5 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "                print('Polygon: Video not from Camera1 or Camera2!')\n",
    "                core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "\n",
    "            # get output video file name\n",
    "            # (XVID is more preferable. MJPG results in high size video. X264 gives very small size video)\n",
    "            # https://docs.opencv.org/3.1.0/dd/d43/tutorial_py_video_display.html\n",
    "            #fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
    "\n",
    "            output_video_sub_dir = os.path.join(output_video_dir, sub_dir)\n",
    "            if not os.path.exists(output_video_sub_dir):\n",
    "                os.makedirs(output_video_sub_dir)\n",
    "\n",
    "            output_video_filename = os.path.join(output_video_sub_dir,'{}_draw_interest_area.avi'.format(f_name.split('.mp4')[0]))\n",
    "            out_camera = cv2.VideoWriter(output_video_filename, int(camera.get(cv2.CAP_PROP_FOURCC)), camera.get(cv2.CAP_PROP_FPS), (original_w, original_h))\n",
    "\n",
    "\n",
    "            # loop over the frames of the video\n",
    "            camera = cv2.VideoCapture(f_path)\n",
    "            total_frame_number = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "            print('Total frame number: {}'.format(total_frame_number))\n",
    "            start_time = time.time()\n",
    "\n",
    "            for frame_count in range(int(total_frame_number)):\n",
    "                # get time\n",
    "                frame_time = camera.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "                if frame_count % 2000 == 0:\n",
    "                    print('Processing frame: {}'.format(frame_count))\n",
    "                    print('Elapsed time: {}s'.format(time.time() - start_time))\n",
    "                (grabbed, frame) = camera.read()\n",
    "                if grabbed == True:\n",
    "\n",
    "                    cv2.drawContours(frame, [whole_interest_area_polygon], -1, (255, 255, 0), 6, cv2.LINE_AA)\n",
    "                    cv2.drawContours(frame, [core_interest_area_polygon], -1, (255, 0, 0), 6, cv2.LINE_AA)\n",
    "\n",
    "                    s_temp = int(frame_time/1000)\n",
    "                    m = s_temp // 60\n",
    "                    s = s_temp % 60\n",
    "                    cv2.putText(frame, \"Original video time: {}m {}s\".format(m, s), (10, 1060), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n",
    "\n",
    "                    if camera_index == 1:\n",
    "                        cv2.putText(frame, \"Camera View\", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4)\n",
    "                        cv2.putText(frame, \"Whole Interest Area\", (left_edge+10, top_edge+80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 0), 4)\n",
    "                        cv2.putText(frame, \"Core Interest\", (point_1[0]+10, point_1[1]+80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 4)\n",
    "                        cv2.putText(frame, \"Area\", (point_1[0]+10, point_1[1]+130), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 4)\n",
    "                    elif camera_index == 2:\n",
    "                        cv2.putText(frame, \"Camera View\", (800, 1000), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4)\n",
    "                        cv2.putText(frame, \"Whole Interest Area\", (left_edge+10, down_edge-50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 0), 4)\n",
    "                        cv2.putText(frame, \"Core Interest Area\", (point_2[0]+10, point_2[1]-50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 4)\n",
    "                    else:\n",
    "                        pass\n",
    "                    # save processed videos\n",
    "                    out_camera.write(frame)\n",
    "                else:\n",
    "                    # Pass this frame if cannot grab an image.\n",
    "                    print('Frame: {}, grabbed={}'.format(frame_count, grabbed))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-v\", \"--video\", default='', help=\"path to the video file\")\n",
    "    ap.add_argument(\"-o\", \"--output_directory\", default='', help=\"directory to save processed video\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    if args.get(\"video\", None) is None:\n",
    "        raise Error(\"No input video!!\")\n",
    "    # otherwise, we are reading from a video file\n",
    "    else:\n",
    "        f_path = args[\"video\"]\n",
    "\n",
    "    f_name = f_path.split('/')[-1]\n",
    "    print(''.format(f_name))\n",
    "    output_video_dir = args['output_directory']#'../ROM_raw_videos_with_interst_area_test'\n",
    "    sub_dir = f_path.split('/')[-2]\n",
    "    \n",
    "    # Get Camera index\n",
    "    camera_index = int(f_name[6])\n",
    "    print('Camera index: {}'.format(camera_index))\n",
    "\n",
    "    # Get frame size\n",
    "    camera = cv2.VideoCapture(f_path)\n",
    "    (grabbed, frame) = camera.read()\n",
    "    original_h, original_w, channels= frame.shape\n",
    "\n",
    "    # Define the polygon of Whole Interest Area for videos from Camera1 or Camera2\n",
    "    if camera_index == 1:\n",
    "        # crop frame: Camera1\n",
    "        top_edge = int(original_h*(1/10))\n",
    "        down_edge = int(original_h*1)\n",
    "        left_edge = int(original_w*(1/5))\n",
    "        right_edge = int(original_w*(4/5))\n",
    "        point_1 = [left_edge, top_edge]\n",
    "        point_2 = [left_edge, down_edge]\n",
    "        point_3 = [right_edge, down_edge]\n",
    "        point_4 = [right_edge, top_edge]\n",
    "        whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "    elif camera_index == 2:\n",
    "        # crop frame: Camera2\n",
    "        top_edge = int(original_h*(1/10))\n",
    "        down_edge = int(original_h*(4/5))\n",
    "        left_edge = int(original_w*(2.5/5))\n",
    "        right_edge = int(original_w*(1))\n",
    "        point_1 = [left_edge, top_edge]\n",
    "        point_2 = [left_edge, down_edge]\n",
    "        point_3 = [right_edge, down_edge]\n",
    "        point_4 = [right_edge, top_edge]\n",
    "        whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "    else:\n",
    "        # crop frame: test video\n",
    "        top_edge = int(original_h*(1/10))\n",
    "        down_edge = int(original_h*1)\n",
    "        left_edge = int(original_w*(1/5))\n",
    "        right_edge = int(original_w*(4/5))\n",
    "        print('Polygon: Video not from Camera1 or Camera2!')\n",
    "        point_1 = [left_edge, top_edge]\n",
    "        point_2 = [left_edge, down_edge]\n",
    "        point_3 = [right_edge, down_edge]\n",
    "        point_4 = [right_edge, top_edge]\n",
    "        whole_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "\n",
    "    # Define the polygon of Core Interest Area for videos from Camera1 or Camera2\n",
    "    cropped_w = right_edge - left_edge\n",
    "    cropped_h = down_edge - top_edge\n",
    "    if camera_index == 1:\n",
    "        # polygon for Camera1\n",
    "        point_1 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        point_2 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.62 * cropped_h)]\n",
    "        point_3 = [left_edge + int(0.44 * cropped_w), top_edge + int(0.82 * cropped_h)]\n",
    "        point_4 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.72 * cropped_h)]\n",
    "        point_5 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "    elif camera_index == 2:\n",
    "        # polygon for Camera2\n",
    "        point_1 = [left_edge + int(0.15 * cropped_w), top_edge + int(0.05 * cropped_h)]\n",
    "        point_2 = [left_edge + int(0.15 * cropped_w), top_edge + int(0.65 * cropped_h)]\n",
    "        point_3 = [left_edge + int(0.95 * cropped_w), top_edge + int(0.75 * cropped_h)]\n",
    "        point_4 = [left_edge + int(0.95 * cropped_w), top_edge + int(0.05 * cropped_h)]\n",
    "        core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4])\n",
    "    else:\n",
    "        # polygon for test video\n",
    "        point_1 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        point_2 = [left_edge + int(0.17 * cropped_w), top_edge + int(0.62 * cropped_h)]\n",
    "        point_3 = [left_edge + int(0.44 * cropped_w), top_edge + int(0.82 * cropped_h)]\n",
    "        point_4 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.72 * cropped_h)]\n",
    "        point_5 = [left_edge + int(0.61 * cropped_w), top_edge + int(0.20 * cropped_h)]\n",
    "        print('Polygon: Video not from Camera1 or Camera2!')\n",
    "        core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "\n",
    "    # get output video file name\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "    output_video_sub_dir = args['output_directory']#os.path.join(output_video_dir, sub_dir)\n",
    "    if not os.path.exists(output_video_sub_dir):\n",
    "        os.makedirs(output_video_sub_dir)\n",
    "\n",
    "    output_video_filename = os.path.join(output_video_sub_dir,'{}_draw_interest_area.avi'.format(f_name.split('.mp4')[0]))\n",
    "    out_camera = cv2.VideoWriter(output_video_filename, fourcc, camera.get(cv2.CAP_PROP_FPS), (original_w, original_h))\n",
    "\n",
    "    # loop over the frames of the video\n",
    "    camera = cv2.VideoCapture(f_path)\n",
    "    total_frame_number = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    print('Total frame number: {}'.format(total_frame_number))\n",
    "    start_time = time.time()\n",
    "\n",
    "    for frame_count in range(int(total_frame_number)):\n",
    "        if frame_count % 2000 == 0:\n",
    "            print('Processing frame: {}'.format(frame_count))\n",
    "            print('Elapsed time: {}s'.format(time.time() - start_time))\n",
    "        (grabbed, frame) = camera.read()\n",
    "        if grabbed == True:\n",
    "\n",
    "            cv2.drawContours(frame, [whole_interest_area_polygon], -1, (255, 255, 0), 6, cv2.LINE_AA)\n",
    "            cv2.drawContours(frame, [core_interest_area_polygon], -1, (255, 0, 0), 6, cv2.LINE_AA)\n",
    "            if camera_index == 1:\n",
    "                cv2.putText(frame, \"Camera View\", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4)\n",
    "                cv2.putText(frame, \"Whole Interest Area\", (left_edge+10, top_edge+80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 0), 4)\n",
    "                cv2.putText(frame, \"Core Interest\", (point_1[0]+10, point_1[1]+80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 4)\n",
    "                cv2.putText(frame, \"Area\", (point_1[0]+10, point_1[1]+130), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 4)\n",
    "            elif camera_index == 2:\n",
    "                cv2.putText(frame, \"Camera View\", (800, 1000), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4)\n",
    "                cv2.putText(frame, \"Whole Interest Area\", (left_edge+10, down_edge-50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 0), 4)\n",
    "                cv2.putText(frame, \"Core Interest Area\", (point_2[0]+10, point_2[1]-50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 4)\n",
    "            else:\n",
    "                pass\n",
    "            # save processed videos\n",
    "            out_camera.write(frame)\n",
    "        else:\n",
    "            # Pass this frame if cannot grab an image.\n",
    "            print('Frame: {}, grabbed={}'.format(frame_count, grabbed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

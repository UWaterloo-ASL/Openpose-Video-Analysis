{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Python\n",
    "# It requires OpenCV installed for Python\n",
    "import sys\n",
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "from sys import platform\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import mode\n",
    "\n",
    "import pdb\n",
    "from IPython.core.debugger import Tracer\n",
    "\n",
    "# Remember to add your installation path here\n",
    "# Option b\n",
    "# If you run `make install` (default path is `/usr/local/python` for Ubuntu), you can also access the OpenPose/python module from there. This will install OpenPose and the python library at your desired installation path. Ensure that this is in your python path in order to use it.\n",
    "sys.path.insert(0,r'/home/lingheng/openpose_python_lib/python/openpose') \n",
    "\n",
    "# Parameters for OpenPose. Take a look at C++ OpenPose example for meaning of components. Ensure all below are filled\n",
    "try:\n",
    "    from openpose import *\n",
    "except:\n",
    "    raise Exception('Error: OpenPose library could not be found. Did you enable `BUILD_PYTHON` in CMake and have this Python script in the right folder?')\n",
    "params = dict()\n",
    "params[\"logging_level\"] = 3\n",
    "params[\"output_resolution\"] = \"-1x-1\"\n",
    "params[\"net_resolution\"] = \"-1x368\" # if crop video, this should be changged and must be mutplies of 16.\n",
    "params[\"model_pose\"] = \"BODY_25\"\n",
    "params[\"alpha_pose\"] = 0.6\n",
    "params[\"scale_gap\"] = 0.3\n",
    "params[\"scale_number\"] = 1\n",
    "params[\"render_threshold\"] = 0.05\n",
    "# If GPU version is built, and multiple GPUs are available, set the ID here\n",
    "params[\"num_gpu_start\"] = 0\n",
    "params[\"disable_blending\"] = False\n",
    "# Ensure you point to the correct path where models are located\n",
    "params[\"default_model_folder\"] = \"/home/lingheng/openpose/models/\"\n",
    "# Construct OpenPose object allocates GPU memory\n",
    "openpose = OpenPose(params)\n",
    "\n",
    "def subplot_estimated_occupancy(occupancy_whole, occupancy_core, occupancy_margin, fig_filename):\n",
    "    \"\"\"\n",
    "    Plot and save estimated occupancy in Three Interest Area.\n",
    "    Args:\n",
    "        occupancy_whole (pd.DataFrame): occupancy in Whole Interest Area\n",
    "        occupancy_core (pd.DataFrame): occupancy in Core Interest Area\n",
    "        occupancy_margin (pd.DataFrame): occupancy in Margin Interest Area\n",
    "        fig_filename (string): filename of the saved figure\n",
    "    \"\"\"\n",
    "    ymin = 0\n",
    "    ymax = 20\n",
    "    ystep = 4\n",
    "    lw=1.5\n",
    "    plt.figure()\n",
    "    # Whole Interest Area\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(occupancy_whole['Time']/1000, occupancy_whole['Occupancy'], 'b-', lw, alpha=0.6)\n",
    "    plt.xlabel('time/second')\n",
    "    plt.ylabel('# of visitors')\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.yticks(np.arange(ymin,ymax,ystep))\n",
    "    plt.title('Estimated # of visitors in Whole Interest Area')\n",
    "    plt.grid(True, linestyle=':')\n",
    "\n",
    "    # Core Interest Area\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(occupancy_core['Time']/1000, occupancy_core['Occupancy'], 'r-', lw, alpha=0.6)\n",
    "    plt.xlabel('time/second')\n",
    "    plt.ylabel('# of visitors')\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.yticks(np.arange(ymin,ymax,ystep))\n",
    "    plt.title('Estimated # of visitors in Core Interest Area')\n",
    "    plt.grid(True, linestyle=':')\n",
    "\n",
    "    # Margin Interest Area\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(occupancy_margin['Time']/1000, occupancy_margin['Occupancy'], 'g-', lw, alpha=0.6)\n",
    "    plt.xlabel('time/second')\n",
    "    plt.ylabel('# of visitors')\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.yticks(np.arange(ymin,ymax,ystep))\n",
    "    plt.title('Estimated # of visitors in Margin Interest Area')\n",
    "    plt.grid(True, linestyle=':')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(fig_filename, dpi = 300)\n",
    "\n",
    "def plot_estimated_occupancy(occupancy_whole, occupancy_core, occupancy_margin, fig_filename):\n",
    "    ymin=0\n",
    "    ymax=20\n",
    "    ystep=4\n",
    "    \n",
    "    plt.figure()\n",
    "    # Whole Interest Area\n",
    "    plt.plot(occupancy_whole['Time']/1000, occupancy_whole['Occupancy'], 'r-', lw=1.5, alpha=0.6)\n",
    "    # Core Interest Area\n",
    "    plt.plot(occupancy_core['Time']/1000, occupancy_core['Occupancy'], 'g-', lw=1.5, alpha=0.6)\n",
    "    # Margin Interest Area\n",
    "    plt.plot(occupancy_margin['Time']/1000, occupancy_margin['Occupancy'], 'b-', lw=1.5, alpha=0.6)\n",
    "    plt.legend(('Whole Interest Area','Core Interest Area','Margin Interest Area'))\n",
    "\n",
    "    plt.xlabel('time/second')\n",
    "    plt.ylabel('# of visitors')\n",
    "    plt.ylim(ymin, ymax, ystep)\n",
    "    plt.title('Estimated # of visitors in Three Interest Areas')\n",
    "    plt.grid(True, linestyle=':')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(fig_filename, dpi = 300)\n",
    "\n",
    "def moving_smoothing(values, window_size, smooth_type='mode', stride = 1):\n",
    "    \"\"\"\n",
    "    Smoothen estimated occupancy.\n",
    "    Args:\n",
    "        values (pandas.DataFrame): \n",
    "            values['Time']: time in millisecond\n",
    "            values['Occupancy']: estimated # of visitors\n",
    "        window_size(int): the size of sliding window\n",
    "        smooth_type (string): \n",
    "            1. 'mode'\n",
    "            2. 'mean'\n",
    "            3. 'min'\n",
    "            4. 'median'\n",
    "        stride (int): the stride between two consecutive windows\n",
    "    Returns:\n",
    "        smooth_time (np.array): smooth time i.e. the max time in each window\n",
    "        smooth_occupancy (np.array): smooth occupancy i.e. the mode occupancy in each window\n",
    "    \"\"\"\n",
    "    group_time = []\n",
    "    group_occupancy = []\n",
    "    for i in range(0, math.ceil((len(values['Time'])-window_size+1)/stride)):\n",
    "        group_time.append(values['Time'][i:i+window_size])\n",
    "        group_occupancy.append(values['Occupancy'][i:i+window_size])\n",
    "    \n",
    "    smooth_time = []\n",
    "    smooth_occupancy = []\n",
    "    for i in range(len(group_time)):\n",
    "        smooth_time.append(min(group_time[i])) # max time in the group\n",
    "        if smooth_type == 'mode':\n",
    "            smooth_occupancy.append(mode(group_occupancy[i])[0][0]) # mode occupancy in the group\n",
    "        elif smooth_type == 'mean':\n",
    "            smooth_occupancy.append(np.round(np.mean(group_occupancy[i])))\n",
    "        elif smooth_type == 'min':\n",
    "            smooth_occupancy.append(np.round(np.min(group_occupancy[i])))\n",
    "        elif smooth_type == 'median':\n",
    "            smooth_occupancy.append(np.round(np.median(group_occupancy[i])))\n",
    "        else:\n",
    "            print('Please choose a proper smooth_type.')\n",
    "    smooth_values = pd.DataFrame(data={'Time': np.array(smooth_time),\n",
    "                                       'Occupancy': np.array(smooth_occupancy,dtype=int)})\n",
    "    return smooth_values#np.array(smooth_time), np.array(smooth_occupancy)\n",
    "\n",
    "def interpret_senario(occupancy_whole, occupancy_core, occupancy_margin, senarios_truth_table):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        occupancy_whole (pd.DataFrame): estimation of coccupancy in whole intrest area\n",
    "        occupancy_core (pd.DataFrame): estimation of coccupancy in core intrest area\n",
    "        occupancy_margin (pd.DataFrame): estimation of coccupancy in margin intrest area\n",
    "        senarios_truth_table (pandas.DataFrame): senarios truth table which has information on\n",
    "            how to interpret senario.\n",
    "    Returns:\n",
    "        senario_sequence (np.array): sequnce of interpreted senario discription according to \"Senario Truth Value Table\"\n",
    "        event_sequence (np.array): sequence of interpreted senario code according to \"Senario Truth Value Table\"\n",
    "            Note: Different from \"Senario Truth Value Table\", in this sequence we convert all impossible cases into 0 rather than their original senario code.\n",
    "        event_time (np.array): the time of each event in millisecond.\n",
    "    \"\"\"\n",
    "    senario_sequence = []\n",
    "    event_sequence = []\n",
    "    event_time = []\n",
    "    for i in range(len(occupancy_whole['Occupancy'])-1):\n",
    "        change_x = occupancy_core['Occupancy'][i+1] - occupancy_core['Occupancy'][i]\n",
    "        change_y = occupancy_margin['Occupancy'][i+1] - occupancy_margin['Occupancy'][i]\n",
    "        change_z = occupancy_whole['Occupancy'][i+1] - occupancy_whole['Occupancy'][i]\n",
    "        # code: \n",
    "        #    0: hold\n",
    "        #    1: increase\n",
    "        #    2: decrease\n",
    "        if change_x == 0:\n",
    "            x = 0\n",
    "        elif change_x > 0:\n",
    "            x = 1\n",
    "        elif change_x < 0:\n",
    "            x = 2\n",
    "\n",
    "        if change_y == 0:\n",
    "            y = 0\n",
    "        elif change_y > 0:\n",
    "            y = 1\n",
    "        elif change_y < 0:\n",
    "            y = 2\n",
    "\n",
    "        if change_z == 0:\n",
    "            z = 0\n",
    "        elif change_z > 0:\n",
    "            z = 1\n",
    "        elif change_z < 0:\n",
    "            z = 2\n",
    "        # convert ternary to decimal\n",
    "        senario_index = z + y*3 + x*3^2\n",
    "        senario_sequence.append(senarios_truth_table['Explanation'][senario_index])\n",
    "        if senarios_truth_table['Truth value'][senario_index] == 0:\n",
    "            # convert all impossible cases into 0\n",
    "            event_sequence.append(0)\n",
    "            #event_sequence.append(senario_index)\n",
    "        else:\n",
    "            event_sequence.append(senario_index)\n",
    "        event_time.append(occupancy_whole['Time'][i])\n",
    "    return np.array(senario_sequence), np.array(event_sequence), np.array(event_time)\n",
    "\n",
    "def plot_detected_interesting_event(senario_sequence, event_sequence, event_time, fig_filename):\n",
    "    ymin = 0\n",
    "    ymax = 26.0005\n",
    "    ystep = 1\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(event_time/1000, event_sequence)\n",
    "    plt.xlabel('time/second')\n",
    "    plt.ylabel('Event Description')\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.yticks(np.arange(ymin,ymax,ystep), senarios_truth_table['Explanation'],\n",
    "               rotation=45, fontsize = 6)\n",
    "    ax2 = plt.twinx()\n",
    "    plt.ylabel('Event Code')\n",
    "    plt.yticks(np.arange(ymin,ymax,ystep), np.arange(ymin,ymax,ystep))\n",
    "    plt.title('Detected Interesting Events')\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_filename, dpi = 300)\n",
    "\n",
    "def tag_interesting_event_description_on_video(video_filename,\n",
    "                                               smooth_type, window_size, stride,\n",
    "                                               senario_sequence, event_sequence, event_time):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        video_filename (string): filename of video\n",
    "        smooth_type (string): smooth type (hyper-parameter of smooth method)\n",
    "        window_size (int): size of smooth window (hyper-parameter of smooth method)\n",
    "        stride (int): stride size (hyper-parameter of smooth method)\n",
    "        senario_sequence (np.array): sequnce of interpreted senario discription according to \"Senario Truth Value Table\"\n",
    "        event_sequence (np.array): sequence of interpreted senario code according to \"Senario Truth Value Table\"\n",
    "            Note: Different from \"Senario Truth Value Table\", in this sequence we convert all impossible cases into 0 rather than their original senario code.\n",
    "        event_time (np.array): the time of each event in millisecond.\n",
    "    \"\"\"\n",
    "    camera = cv2.VideoCapture(video_filename)\n",
    "    (grabbed, frame) = camera.read()\n",
    "    fheight, fwidth, channels= frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out_tagged_camera_frame = cv2.VideoWriter(video_filename.split('.avi')[0]+'_tagged_smooth_type_{}_window_size_{}_stride_{}.avi'.format(smooth_type,window_size,stride),fourcc, camera.get(cv2.CAP_PROP_FPS), (fwidth,fheight))\n",
    "    # loop over the frames of the video\n",
    "    total_frame_number = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    max_line_character_num = 60 # 60 characters each line\n",
    "    detected_event_time = 0\n",
    "    detected_event_senario = ''\n",
    "    line_num = 1\n",
    "    for frame_count in range(len(event_time)):\n",
    "        if frame_count % 200 == 0:\n",
    "            print('Processing frame: {}'.format(frame_count))\n",
    "        (grabbed, frame) = camera.read()\n",
    "        if grabbed == True:\n",
    "            cv2.putText(frame, \"smooth_type: {}, window_size: {}, stride: {}.\".format(smooth_type,window_size,stride), (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            time = camera.get(cv2.CAP_PROP_POS_MSEC) #Current position of the video file in milliseconds.\n",
    "            event_index = frame_count\n",
    "            if event_sequence[event_index] != 0: # 0 means 'impossible event'\n",
    "                detected_event_time = time\n",
    "                detected_event_senario = senario_sequence[event_index]\n",
    "                cv2.putText(frame, \"Detect Interesting Event at: {}s.\".format(int(detected_event_time/1000)), (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                line_num = np.ceil(len(detected_event_senario)/max_line_character_num)\n",
    "                for i in range(int(line_num)):\n",
    "                    if i < line_num:\n",
    "                        cv2.putText(frame, \"{}\".format(detected_event_senario[i*max_line_character_num:(i+1)*max_line_character_num]), (10, 180+30*(i)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                    else:\n",
    "                        cv2.putText(frame, \"{}\".format(detected_event_senario[i*max_line_character_num:end]), (10, 180+30*(i)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            else: # repeat text from last detected event\n",
    "                cv2.putText(frame, \"Interesting Event Time: {}s\".format(int(detected_event_time/1000)), (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                for i in range(int(line_num)):\n",
    "                    if i < line_num:\n",
    "                        cv2.putText(frame, \"{}\".format(detected_event_senario[i*max_line_character_num:(i+1)*max_line_character_num]), (10, 180+30*(i)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                    else:\n",
    "                        cv2.putText(frame, \"{}\".format(detected_event_senario[i*max_line_character_num:end]), (10, 180+30*(i)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            # save processed videos\n",
    "            out_tagged_camera_frame.write(frame)\n",
    "        else:\n",
    "            # Pass this frame if cannot grab an image.\n",
    "            print('Frame: {}, grabbed={} and frame={}'.format(frame_count, grabbed, frame))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # construct the argument parser and parse the arguments\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-v\", \"--video\", default='/home/lingheng/project/lingheng/ROM_raw_videos/Camera1_test.mp4', help=\"path to the video file\")\n",
    "    ap.add_argument(\"-o\", \"--output_directory\", default='/home/lingheng/project/lingheng/ROM_processed_videos', help=\"directory to save processed video\")\n",
    "    \n",
    "    args = vars(ap.parse_args())\n",
    "    \n",
    "    if args.get(\"video\", None) is None:\n",
    "        raise Error(\"No input video!!\")\n",
    "    # otherwise, we are reading from a video file\n",
    "    else:\n",
    "        camera = cv2.VideoCapture(args[\"video\"])\n",
    "    ########################################################################\n",
    "    #                         Estimate Occupancy                           #\n",
    "    ########################################################################\n",
    "    # frames per second (fps) in the raw video\n",
    "    fps = camera.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 1\n",
    "    print(\"Raw frames per second: {0}\".format(fps))\n",
    "    # prepare to save video\n",
    "    (grabbed, frame) = camera.read()\n",
    "    # downsample frame\n",
    "    downsample_rate = 0.5\n",
    "    frame = cv2.resize(frame,None,fx=downsample_rate, fy=downsample_rate, interpolation = cv2.INTER_LINEAR)\n",
    "    # crop frame\n",
    "    original_h, original_w, channels= frame.shape\n",
    "    top_edge = int(original_h*(1/10))\n",
    "    down_edge = int(original_h*1)\n",
    "    left_edge = int(original_w*(1/5))\n",
    "    right_edge = int(original_w*(4/5))\n",
    "    frame_cropped = frame[top_edge:down_edge,left_edge:right_edge,:].copy() # must use copy(), otherwise slice only return address i.e. not hard copy\n",
    "\n",
    "    cropped_h, cropped_w, channels = frame_cropped.shape\n",
    "    fwidth = cropped_w \n",
    "    fheight = cropped_h\n",
    "    print(\"Frame width:{}, Frame height:{}.\".format(cropped_w , cropped_h))\n",
    "    # Define the polygon of Core Interest Area\n",
    "    point_1 = [int(0.17 * cropped_w), int(0.20 * cropped_h)]\n",
    "    point_2 = [int(0.17 * cropped_w), int(0.62 * cropped_h)]\n",
    "    point_3 = [int(0.44 * cropped_w), int(0.82 * cropped_h)]\n",
    "    point_4 = [int(0.61 * cropped_w), int(0.72 * cropped_h)]\n",
    "    point_5 = [int(0.61 * cropped_w), int(0.20 * cropped_h)]\n",
    "    core_interest_area_polygon = np.array([point_1,point_2,point_3,point_4,point_5])\n",
    "\n",
    "    # get output video file name\n",
    "    file_path = args[\"video\"].split('/')\n",
    "    file_name, _= file_path[-1].split('.')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "    output_video_filename = os.path.join(args['output_directory'],'{}_processed.avi'.format(file_name))\n",
    "    out_camera_frame_whole = cv2.VideoWriter(output_video_filename,fourcc, fps, (fwidth,fheight))\n",
    "\n",
    "    # get output estimated occupancy file name\n",
    "    out_occupancy_whole = os.path.join(args['output_directory'],'{}_processed_occupancy_whole.csv'.format(file_name))\n",
    "    out_occupancy_core = os.path.join(args['output_directory'],'{}_processed_occupancy_core.csv'.format(file_name))\n",
    "    out_occupancy_margin = os.path.join(args['output_directory'],'{}_processed_occupancy_margin.csv'.format(file_name))\n",
    "    with open(out_occupancy_whole, 'a') as csv_datafile:\n",
    "        fieldnames = ['Time', 'Occupancy']\n",
    "        writer = csv.DictWriter(csv_datafile, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "    with open(out_occupancy_core, 'a') as csv_datafile:\n",
    "        fieldnames = ['Time', 'Occupancy']\n",
    "        writer = csv.DictWriter(csv_datafile, fieldnames = fieldnames)\n",
    "        writer.writeheader()    \n",
    "    with open(out_occupancy_margin, 'a') as csv_datafile:\n",
    "        fieldnames = ['Time', 'Occupancy']\n",
    "        writer = csv.DictWriter(csv_datafile, fieldnames = fieldnames)\n",
    "        writer.writeheader()      \n",
    "    \n",
    "    # loop over the frames of the video\n",
    "    total_frame_number = camera.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    for frame_count in range(int(total_frame_number)):\n",
    "        if frame_count % 200 == 0:\n",
    "            print('Processing frame: {}'.format(frame_count))\n",
    "        (grabbed, frame) = camera.read()\n",
    "        if grabbed == True:\n",
    "            time = camera.get(cv2.CAP_PROP_POS_MSEC) #Current position of the video file in milliseconds.\n",
    "            # downsample frame\n",
    "            frame = cv2.resize(frame,None,fx=downsample_rate, fy=downsample_rate, interpolation = cv2.INTER_LINEAR)\n",
    "            # crop frame\n",
    "            frame_cropped = frame[top_edge:down_edge,left_edge:right_edge,:].copy() # must use copy()\n",
    "\n",
    "            # 1. Whole Interest Area\n",
    "            # Output keypoints and the image with the human skeleton blended on it\n",
    "            #    (num_people, 25_keypoints, x_y_confidence) = keypoints_whole_interest_area.shape\n",
    "            keypoints_whole_interest_area, output_image_whole_interest_area = openpose.forward(frame_cropped, True)\n",
    "\n",
    "            # 2. Core Interest Area\n",
    "            core_interest_area_mask = np.zeros(frame_cropped.shape[:2], np.uint8)\n",
    "            cv2.drawContours(core_interest_area_mask, [core_interest_area_polygon], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "            core_interest_area = cv2.bitwise_and(output_image_whole_interest_area, frame_cropped, mask=core_interest_area_mask)\n",
    "\n",
    "            # 3. Margin Interest Area\n",
    "            margin_interest_area = cv2.bitwise_xor(output_image_whole_interest_area, core_interest_area)\n",
    "            # TODO: infer occupancy from \"keypoints_whole_interest_area\"\n",
    "\n",
    "            # draw the text and timestamp on the frame\n",
    "            occupancy_whole = keypoints_whole_interest_area.shape[0]\n",
    "            occupancy_core = 0\n",
    "            occupancy_margin = 0\n",
    "            for people in keypoints_whole_interest_area:\n",
    "                # Sort all keypoints and pick up the one with the highest confidence\n",
    "                # Meaning of keypoints (https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/output.md)\n",
    "                ordered_keypoints = people[people[:,2].argsort(),:] # increasing order\n",
    "                x, y = ordered_keypoints[-1][:2]\n",
    "                #pdb.set_trace()\n",
    "                # Choose the one with higher confidence to calculatate occupancy and location\n",
    "                if cv2.pointPolygonTest(core_interest_area_polygon, (x, y), False) == 1:\n",
    "                    occupancy_core += 1\n",
    "                else:\n",
    "                    occupancy_margin += 1\n",
    "\n",
    "            cv2.drawContours(output_image_whole_interest_area, [core_interest_area_polygon], -1, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(output_image_whole_interest_area, \"Whole Occupancy: {}, Core Occupancy: {}, Margin Occupancy: {}\".format(occupancy_whole, occupancy_core, occupancy_margin), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(core_interest_area, \"Core Occupancy: {}\".format(occupancy_core), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            cv2.putText(margin_interest_area, \"Margin Occupancy: {}\".format(occupancy_margin), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            # save estimated occupancy data\n",
    "            fieldnames = ['Time', 'Occupancy']\n",
    "            with open(out_occupancy_whole, 'a') as csv_datafile:\n",
    "                writer = csv.DictWriter(csv_datafile, fieldnames = fieldnames)\n",
    "                writer.writerow({'Time':time, 'Occupancy': occupancy_whole})\n",
    "            with open(out_occupancy_core, 'a') as csv_datafile:\n",
    "                writer = csv.DictWriter(csv_datafile, fieldnames = fieldnames)\n",
    "                writer.writerow({'Time':time, 'Occupancy': occupancy_core})\n",
    "            with open(out_occupancy_margin, 'a') as csv_datafile:\n",
    "                writer = csv.DictWriter(csv_datafile, fieldnames = fieldnames)\n",
    "                writer.writerow({'Time':time, 'Occupancy': occupancy_margin})\n",
    "            # save processed videos\n",
    "            out_camera_frame_whole.write(output_image_whole_interest_area)\n",
    "        else:\n",
    "            # Pass this frame if cannot grab an image.\n",
    "            print('Frame: {}, grabbed={} and frame={}'.format(frame_count, grabbed, frame))\n",
    "\n",
    "    ########################################################################\n",
    "    #    Smoothen Estimated Occupancy, then detect interesting event       #\n",
    "    ########################################################################\n",
    "    \n",
    "    # read estimated occupancy in Three Interest Areas\n",
    "    occupancy_whole = pd.read_csv(out_occupancy_whole)\n",
    "    occupancy_core = pd.read_csv(out_occupancy_core)\n",
    "    occupancy_margin = pd.read_csv(out_occupancy_margin)\n",
    "\n",
    "    # save plot of estimated occupancy in Three Interest Areas\n",
    "    fig_filename = 'Subplot_Estimated_Occupancy.png'\n",
    "    subplot_estimated_occupancy(occupancy_whole, occupancy_core, occupancy_margin, fig_filename)\n",
    "    fig_filename = 'Plot_Estimated_Occupancy.png'\n",
    "    plot_estimated_occupancy(occupancy_whole, occupancy_core, occupancy_margin, fig_filename)\n",
    "    \n",
    "    # smoothen\n",
    "    window_size = 25\n",
    "    smooth_type='mean'\n",
    "    stride = 1\n",
    "    smooth_occupancy_whole = moving_smoothing(occupancy_whole, window_size, smooth_type)\n",
    "    smooth_occupancy_core = moving_smoothing(occupancy_core, window_size, smooth_type)\n",
    "    smooth_occupancy_margin = moving_smoothing(occupancy_margin, window_size, smooth_type)\n",
    "\n",
    "    fig_filename = 'Subplot_Smooth_Estimated_Occupancy.png'\n",
    "    subplot_estimated_occupancy(smooth_occupancy_whole,smooth_occupancy_core,smooth_occupancy_margin, fig_filename)\n",
    "    fig_filename = 'Plot_Smooth_Estimated_Occupancy.png'\n",
    "    plot_estimated_occupancy(smooth_occupancy_whole,smooth_occupancy_core,smooth_occupancy_margin, fig_filename)\n",
    "    \n",
    "    # load Senario Truth Table\n",
    "    senarios_truth_table = pd.read_csv('analize_visitor_in_and_out_senario_truth_table.csv')\n",
    "    \n",
    "    # Interpret\n",
    "    senario_sequence, event_sequence, event_time = interpret_senario(smooth_occupancy_core, \n",
    "                                                                     smooth_occupancy_margin, \n",
    "                                                                     smooth_occupancy_whole, \n",
    "                                                                     senarios_truth_table)\n",
    "    # Plot interesting events\n",
    "    fig_filename = 'Plot_Interesting_Event_smooth_type_{}_window_size_{}_stride{}'.format(smooth_type, window_size, stride)\n",
    "    plot_detected_interesting_event(senario_sequence, event_sequence, event_time, fig_filename)\n",
    "    \n",
    "    # Tag\n",
    "    tag_interesting_event_description_on_video(output_video_filename, \n",
    "                                               smooth_type, window_size, stride,\n",
    "                                               senario_sequence, event_sequence, event_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
